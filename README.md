# SmartChat - Assistente Virtual com RAG

![Java](https://img.shields.io/badge/Java-17%2B-blue)
![Spring Boot](https://img.shields.io/badge/Spring_Boot-3.1-green)
![Docker](https://img.shields.io/badge/Docker-‚úì-blue)

## üìù Vis√£o Geral

Este projeto implementa a t√©cnica **RAG (Retrieval Augmented Generation)** para responder perguntas com base em contexto armazenado em um mecanismo de busca vetorial (Azure Search). Utiliza-se o modelo GPT da OpenAI para gera√ß√£o de respostas mais ricas e personalizadas.

### Tecnologias Principais:

- Java + Spring Boot
- Spring Cloud OpenFeign
- OpenAI Embeddings + GPT
- Banco de dados vetorial Azure AI Search
- Banco de dados relacional H2
- Docker

---

## üöÄ Come√ßando

### Pr√©-requisitos

- Docker
- Java 17+ (caso queira rodar sem Docker)
- Chave de API da OpenAI
- Token da Azure Cognitive Search com √≠ndice previamente configurado e populado

### ‚öôÔ∏è Executando o Projeto

### 1. Clone o reposit√≥rio:
```
git clone https://github.com/fabiobastian/SmartChat.git
cd SmartChat
```

### 2. Fa√ßa o build da imagem usando docker
```
docker build -t smartchat . 
```

### 3. Configure as vari√°veis de ambiente:

Crie um arquivo **.env** na raiz do projeto com o seguinte conte√∫do:
```
OPENAI_API_KEY=<sua_chave_aqui>
AZURE_SEARCH_API_KEY=<sua_chave_aqui>
```
A cria√ß√£o do .env √© opcional, mas facilita a execu√ß√£o do cont√™iner.

### 4. Execute o cont√™iner com Docker

Com **.env**
```
docker run -d --env-file .env -p 8080:8080 smartchat
```
Sem **.env**
```
docker run -d -p 8080:8080 -e "OPENAI_API_KEY=<sua_chave_aqui>" -e "AZURE_SEARCH_API_KEY=<sua_chave_aqui>" smartchat
```

## üåê Acessos √öteis

### Swagger

http://localhost:8080/swagger-ui/index.html

Interface para testar facilmente os endpoints da API.

### Console H2

http://localhost:8080/h2-console

Banco relacional em mem√≥ria (estilo SQLite) embutido no Spring Boot. S√≥ estar√° acess√≠vel enquanto a aplica√ß√£o estiver em execu√ß√£o.

Configura√ß√µes de acesso:

- Driver Class:	org.h2.Driver
- JDBC URL: jdbc:h2:file:/app/data/h2db
- User Name: sa
- Password: (deixe em branco)

Se estiver rodando fora do Docker, altere o **JDBC URL** para:

jdbc:h2:file:./data/h2db

As configura√ß√µes podem ser personalizadas no arquivo application.properties.

## üß† Principais Decis√µes T√©cnicas

### Java + Spring Boot

- Produtividade com robustez: Usei Java com Spring Boot por oferecer rapidez no desenvolvimento de APIs RESTful com qualidade de produ√ß√£o. A estrutura do framework favorece a organiza√ß√£o do projeto em camadas bem definidas.

- Feign Client para comunica√ß√£o externa: Escolhi OpenFeign por permitir chamadas HTTP limpas e tipadas, facilitando a integra√ß√£o com a API da OpenAI com pouco c√≥digo e alta legibilidade.

- F√°cil integra√ß√£o com banco de dados, e op√ß√µes de banco de dados como o H2 que se integra muito bem com o JPA, mantendo a modularidade, podendo ser migrado facilmente para bancos de dados como PostgreSQL ou Oracle.

### Embeddings

- Problema: Recebo diversas mensagens, como as devo processar?

Para resolver este problema adotei a estrat√©gia de, unir todas as mensagens vindas por meio da rule=user, e remover as sauda√ß√µes do usu√°rio, como Hello, Morning, etc. Retiro as sauda√ß√µes por elas n√£o trazerem um valor sem√¢ntico a frase, com est√° grande frase fa√ßo o embedding e posteriormente pesquiso as perguntas+respostas correspondentes no Azure.

Posteriormente com todas as informa√ß√µes em m√£os, fa√ßo o prompt para enviar para o ChatGPT, por√©m n√£o envio a mensagem com as sauda√ß√µes retiradas, envio a mensagem original do usu√°rio, para que assim a IA consiga responder da forma mais natural poss√≠vel, saudando o usu√°rio de volta.

### Escalar para N2

- Problema: Em qual momento, e qual estrat√©gia devo utilizar para escalar o problema para N2?

Adotei a estrat√©gia de **Option 2: Handover Feature**, que basicamente diz que: quando o banco vetorial retornar uma resposta do type=N2, o atendimento deve ser escalado para um atendente humano, enviando o handoverToHumanNeeded: true na resposta.

Acredito que por se tratar de uma POC est√° seja a solu√ß√£o mais vi√°vel, por conta da feature de esclarecimento n√£o estar muito clara quais devem ser os par√¢metros utilizados, e ser muito mais ligada a regras de neg√≥cio.

### Banco de Dados

![diagrama ER](./documents/ER_diagram.png)

Escolhi por implementar um banco de dados relacional na minha aplica√ß√£o, acredito que numa implementa√ß√£o maior, utilizando microsservi√ßos, est√° minha API seja apenas um pequeno peda√ßo com responsabilidade limitada a gera√ß√£o de respostas a partir de uma entrada bem definida.

Por√©m, como gostaria de mostrar mais o que sei, decide fazer um ecosistema maior, com mais responsabilidades, como a ger√™ncia de projetos conforme o project.name, e com isso ter o controle das diferentes mensagens, conversas e tamb√©m guardar os contextos resgatadas da Azure.

Com este esquema de banco de dados √© poss√≠vel cadastrar mais projetos, conforme o nome e ‚Äòslogan‚Äô do cliente, mudando assim onde √© buscado na Azure e a quem a IA responde como assistente.

Tamb√©m √© poss√≠vel ter o hist√≥rico completo de conversar, e mensagens trocadas entre o usu√°rio e o assistente(IA), podendo assim retornar ao cliente no front de forma simples.

Com o hist√≥rico de mensagens trocadas e os contextos resgatados salvos, podemos assim se for preciso, antes mesmo de receber a pergunta do usu√°rio, podemos contextualizar a IA para assim receber a resposta mais precisa, tamb√©m pode ser projetado para d√≠gamos, sempre contextualizar a IA com as √∫ltimas perguntas feitas num intervalo de 15 minutos, assim utilizando na resposta um contexto mais amplo.

Seguindo mais no √¢mbito do chatbox, usando as perguntas feitas pelo usu√°rio, os contextos resgatados, e as respostas dada pelo assistente(IA), conseguimos avaliar a assertividade do modelo, utilizando IAs treinadas para avaliar as respostas, e assim dar nota para cada resposta/atendimento.

## Aprimoramentos Identificados

1. Processamento Avan√ßado de Mensagens

Atualmente, as mensagens do usu√°rio s√£o concatenadas antes de gerar embeddings, o que pode diluir o contexto em conversas com m√∫ltiplos t√≥picos. Uma melhoria seria:

Embedding por mensagem: Gerar vetores individuais para cada entrada do usu√°rio, permitindo identificar perguntas distintas e responder de forma mais direcionada.

Agrupamento sem√¢ntico: Usar similaridade vetorial (ex: cosine similarity) para agrupar mensagens relacionadas e tratar t√≥picos separadamente.

2. Aprimoramento do Contexto

Sele√ß√£o din√¢mica de contexto: Priorizar trechos relevantes com base na √∫ltima mensagem, mantendo hist√≥rico curto para evitar polui√ß√£o.

HyDE (Hypothetical Document Embeddings): Gerar uma resposta hipot√©tica antes da busca vetorial, refinando a recupera√ß√£o de informa√ß√µes.

3. Controle de Fluxo da Conversa

Detec√ß√£o de mudan√ßa de t√≥pico: Alertar o usu√°rio quando perguntas n√£o relacionadas forem detectadas (ex: "Parece que mudou de assunto. Devo focar na √∫ltima pergunta?").

Respostas multifacetadas: Para consultas com v√°rios temas, segmentar a resposta claramente (ex: "Sobre X: [...]. Sobre Y: [...]").

4. Aprimoramento no Tratamento de Erros

Respostas de erro mais descritivas e personalizadas, substituindo as mensagens gen√©ricas dos validators (@NotBlank, @Min, etc.) por explica√ß√µes claras e orienta√ß√µes para corre√ß√£o.

5. Sistema de Hist√≥rico de Conversas
   
Seria interessante ter um endpoint dedicado para recupera√ß√£o do hist√≥rico completo das intera√ß√µes, permitindo:

- Consulta por ID de conversa
- Filtragem por per√≠odo espec√≠fico

6. Melhoria na Observabilidade

Pode ser implementado logs estruturados com @Slf4j para o melhor controle do fluxo na aplica√ß√£o, que permite:

- Rastreamento do fluxo de processamento
- Identifica√ß√£o r√°pida de pontos de falha
- Monitoramento de desempenho por etapa (embedding, busca, gera√ß√£o)

## Fluxo do Chatbot

- Recebe a pergunta do usu√°rio
- Gera embeddings da pergunta
- Busca trechos relevantes no banco vetorial
- Envia pergunta + contexto para o LLM gerar a resposta

## Fluxo ConversationService (service principal)

![Diagrama de Sequ√™ncia UML](./documents/UML_diagrama.png)

## üìå Observa√ß√µes

- O banco H2 j√° vem cadastrada com o cliente Tesla Motors, por√©m se foi exclu√≠do ou perdeu-se de alguma forma, para recuperar esse registro **essencial**, s√≥ basta executar o insert do arquivo **data/data.sql** no console do H2.
- A cada nova mensagem enviada, caso o **helpdeskId** ainda n√£o tenha sido cadastrado, sinalizando que √© a primeira mensagem, ser√° cadastrado uma nova conversa, e assim as pr√≥ximas mensagens que vierem com este **helpdeskId** ser√£o associadas a conversa criada.
- Certifique-se de que o √≠ndice no Azure Search j√° est√° criado e populado antes de iniciar a aplica√ß√£o.
- A aplica√ß√£o est√° configurada para ser facilmente executada via Docker, mas tamb√©m pode rodar localmente com Maven.